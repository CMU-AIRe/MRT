# Direct Evaluation Documentation

## Overview

The `eval_direct.py` script performs direct evaluation of language models on mathematical problems. Given a query, the model generates responses.

## Key Parameters

### Required Parameters

- `model_path`: Path to the model

  - Example: `hf-cmu-collab/Llama-3.1-8B-Instruct-sft_conversations-v00.00`

- `dataset_name` and `dataset_split`: Specify the evaluation dataset

  - Supported dataset: `hf-cmu-collab/metaMATH_eval_direct`
  - Available splits: `Train`, `Test`, `AIME`, `MATH500`

- `env`: Instruction format

  - For non-finetuned models (e.g., meta-llama/Llama-3.1-8B-Instruct):
    - `MATH-0-shot`
    - `MATH-1-shot`
    - `MATH-4-shot`
  - For all other models:
    - `backtrack`

- `output_path`: Path where the evaluation logs will be saved

### Optional Parameters

- `num_samples`: Number of samples to generate per prompt (default: 10)
- `temperature`: Sampling temperature (default: 0.7)
- `max_tokens`: Maximum number of tokens in generated response (default: 2048)
- `randomize`: Whether to randomize the dataset (default: False)
- `dataset_start`: Starting index in dataset (default: None)
- `dataset_end`: Ending index in dataset (default: None)

## Example Usage

```bash
# Variables
model_name=Llama-3.1-8B-Instruct-sft_conversations-v00.00
model_path=hf-cmu-collab/Llama-3.1-8B-Instruct-sft_conversations-v00.00
task=AIME
dataset_name=hf-cmu-collab/metaMATH_eval_direct
dataset_split=AIME
env=backtrack
output_path="direct_${task}_${model_name}_pass10.log"

# Command
python eval_direct.py \
    --model_path ${model_path} \
    --dataset_name ${dataset_name} \
    --dataset_split ${dataset_split} \
    --env ${env} \
    --output_path ${output_path} \
    --num_samples 10 \
    --temperature 0.7 \
    --max_tokens 4096
```

# History Conditioned Evaluation Documentation

## Overview

The `eval_history_conditioned.py` script evaluates language models on mathematical problems using historical context. For each query, the model generates responses based on:

- The original query
- A (partial) rollout generated by the base model
- A backtrack sentence (optional)

## Key Parameters

### Required Parameters

- `model_path`: Path to the model

  - Example: `hf-cmu-collab/Llama-3.1-8B-Instruct-sft_suffix-v03.00`

- `dataset_name` and `dataset_split`: Specify the evaluation dataset

  - Supported dataset: `hf-cmu-collab/metaMATH_eval_history_conditioned`
  - Available splits: `Train`, `Test`, `AIME`, `MATH500`

- `env`: Instruction format

  - `backtrack`

- `column_name`: Prefix type for evaluation (should match finetuning data)

  - `resample_from_beginning`
  - `backtrack_with_shared_prefix`
  - `backtrack_without_shared_prefix`
  - `backtrack_without_full_rollout`

- `given_backtrack`: Controls backtrack sentence generation

  - Default: `True`
  - Set to `False` only when evaluating models finetuned with:
    - `hf-cmu-collab/metaMATH_t0_n1_backtrack_with_shared_prefix_explicit_backtrack_0113`
    - `hf-cmu-collab/metaMATH_t0_n1_backtrack_with_shared_prefix_implicit_backtrack_0113`
  - When `False`, the model will not be given the backtrack sentence and it generates both the backtrack sentence and second rollout

- `output_path`: Path where the evaluation logs will be saved

### Optional Parameters

- `num_samples`: Number of samples to generate (default: 10)
- `temperature`: Sampling temperature (default: 0.7)
- `max_tokens`: Maximum number of tokens in generated response (default: 2048)
- `randomize`: Whether to randomize the dataset (default: False)
- `dataset_start`: Starting index in dataset (default: None)
- `dataset_end`: Ending index in dataset (default: None)

## Example Usage

```bash
# Variables
model_name=Llama-3.1-8B-Instruct-sft_suffix-v03.00
model_path=hf-cmu-collab/Llama-3.1-8B-Instruct-sft_suffix-v03.00
column_name=backtrack_without_shared_prefix
task=AIME
dataset_name=hf-cmu-collab/metaMATH_history_conditioned
dataset_split=train
env=backtrack
output_path="history_conditioned_${task}_${model_name}_pass10.log"

# Command
python eval_history_conditioned.py \
    --model_path ${model_path} \
    --dataset_name ${dataset_name} \
    --dataset_split ${dataset_split} \
    --env ${env} \
    --column_name ${column_name} \
    --given_backtrack False \
    --output_path ${output_path} \
    --num_samples 10 \
    --temperature 0.7 \
    --max_tokens 4096
```
